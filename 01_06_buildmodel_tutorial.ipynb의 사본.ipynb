{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"KtvLywPixvUW","executionInfo":{"status":"ok","timestamp":1663898465062,"user_tz":-540,"elapsed":1918,"user":{"displayName":"유태종","userId":"14183084913974218146"}}},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"1re9-2vvxvUZ"},"source":["# 신경망 모델 구성하기\n","\n","신경망은 데이터에 대한 연산을 수행하는 계층(layer)/모듈(module)로 구성되어 있다.\n","[`torch.nn`](<https://pytorch.org/docs/stable/nn.html>) 네임스페이스는 신경망을 구성하는데 필요한 모든 구성 요소를 제공한다.\n","PyTorch의 모든 모듈은 [`nn.Module`](<https://pytorch.org/docs/stable/generated/torch.nn.Module.html>)의 하위 클래스(subclass)\n","이다. 신경망은 그 자체로 다른 모듈 혹은 계층(layer)들로 구성된 하나의 모듈이다. 이러한 중첩된 구조는 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있게 한다.\n","\n","이제 FashionMNIST 데이터셋의 이미지들을 분류하는 신경망을 구성해보자.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NA5QZhvCxvUb","executionInfo":{"status":"ok","timestamp":1663898471280,"user_tz":-540,"elapsed":6220,"user":{"displayName":"유태종","userId":"14183084913974218146"}}},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","metadata":{"id":"XtgxApsSxvUc"},"source":["학습을 위한 장치 얻기\n","------------------------------------------------------------------------------------------\n","\n","가능하다면 GPU와 같은 하드웨어 가속기에서 모델을 학습하는 것이 효율적이다.\n","[`torch.cuda`](<https://pytorch.org/docs/stable/notes/cuda.html>)를 사용할 수 있는지\n","확인하고 그렇지 않으면 CPU를 계속 사용한다."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RuGYC16_xvUc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663898471280,"user_tz":-540,"elapsed":18,"user":{"displayName":"유태종","userId":"14183084913974218146"}},"outputId":"c2fddd26-1e81-45b2-ffdf-740fcb66d128"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"iz00Sqj2xvUd"},"source":["클래스 정의하기\n","------------------------------------------------------------------------------------------\n","\n","신경망 모델을 ``nn.Module``의 하위클래스로 정의하고, ``__init__``에서 신경망 계층들을 초기화한다.\n","``nn.Module``을 상속받은 모든 클래스는 ``forward`` 메소드에 입력 데이터에 대한 연산들을 구현한다.\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tLPYeBVHxvUd","executionInfo":{"status":"ok","timestamp":1663898471280,"user_tz":-540,"elapsed":5,"user":{"displayName":"유태종","userId":"14183084913974218146"}}},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"rJeC_YlFxvUe"},"source":["``NeuralNetwork``의 인스턴스(instance)를 생성하고 이를 ``device``로 이동한 뒤,\n","구조(structure)를 출력한다.\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0QOunk85xvUf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663898523377,"user_tz":-540,"elapsed":12076,"user":{"displayName":"유태종","userId":"14183084913974218146"}},"outputId":"c942296e-df39-4be4-ed91-8d396ddd3db9"},"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["model = NeuralNetwork().to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"h5NYBMzwxvUg"},"source":["모델에 입력 데이터를 전달하면 약간의\n","[백그라운드 연산들](<https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866>)과 함께\n","모델의 ``forward`` 메서드가 자동으로 실행된다. ``model.forward()``를 사용자가 직접 호출하지는 않는다.\n","\n","입력 데이터에 대해 모델을 실행하면 각 분류(class)에 대한 원시(raw) 예측값이 저장된 10-차원 텐서가 반환된다. 원시 예측값을 ``nn.Softmax`` 모듈의 인스턴스에 통과시켜 예측 확률을 얻는다.\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"XAnnLarGxvUh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663898523378,"user_tz":-540,"elapsed":16,"user":{"displayName":"유태종","userId":"14183084913974218146"}},"outputId":"16cf1074-d68b-47a6-8073-db2755b34cc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: tensor([5], device='cuda:0')\n"]}],"source":["X = torch.rand(1, 28, 28, device=device) # should actually be 1, 1, 28, 28 but torch understands this fine\n","logits = model(X)\n","pred_probab = nn.Softmax(dim=1)(logits) # not strictly necessary here\n","# softmax: maps each inputs to [0,1] such that inputs' size relation is preserved and sum of them is 1\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted class: {y_pred}\")"]},{"cell_type":"markdown","metadata":{"id":"L0RSMATSxvUh"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pJcCD9jexvUi"},"source":["모델 계층(Layer)\n","------------------------------------------------------------------------------------------\n","\n","FashionMNIST 모델의 계층들을 살펴보자. 이를 설명하기 위해, 28x28 크기의 랜덤 이미지 3개로 구성된\n","미니배치를 가져와, 신경망을 통과할 때 어떤 일이 발생하는지 알아본다.\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"wUhuRevXxvUi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663898548978,"user_tz":-540,"elapsed":3,"user":{"displayName":"유태종","userId":"14183084913974218146"}},"outputId":"a0fe06f2-d044-42a5-cf47-4e45b03e23c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[9.9928e-01, 2.0988e-01, 5.9473e-01,  ..., 8.8738e-01,\n","           7.3325e-01, 4.1946e-01],\n","          [8.9353e-01, 6.7821e-01, 2.7026e-01,  ..., 4.5129e-01,\n","           1.0666e-01, 3.8061e-01],\n","          [2.9219e-01, 4.9672e-01, 3.3059e-01,  ..., 5.8252e-01,\n","           1.1636e-01, 6.8737e-01],\n","          ...,\n","          [3.1693e-01, 2.3180e-01, 6.1635e-03,  ..., 7.0889e-01,\n","           5.9139e-01, 4.3429e-01],\n","          [9.7392e-01, 4.8667e-01, 1.1410e-01,  ..., 8.4743e-01,\n","           4.3024e-01, 6.8225e-01],\n","          [5.6175e-01, 9.0237e-01, 5.5603e-01,  ..., 3.5364e-01,\n","           2.0274e-01, 3.9082e-01]],\n","\n","         [[6.8753e-01, 8.5767e-01, 4.3355e-01,  ..., 3.3315e-01,\n","           2.6087e-01, 5.7910e-01],\n","          [6.1294e-01, 8.2156e-01, 1.3153e-01,  ..., 4.7208e-01,\n","           8.9910e-01, 5.9171e-02],\n","          [9.3229e-01, 6.2257e-01, 4.7749e-01,  ..., 7.0579e-01,\n","           7.1962e-01, 8.6955e-01],\n","          ...,\n","          [6.5623e-01, 4.5831e-03, 7.5773e-01,  ..., 2.7293e-01,\n","           8.8956e-01, 6.7566e-01],\n","          [3.8972e-01, 7.0558e-01, 8.1775e-01,  ..., 2.5302e-01,\n","           8.2179e-01, 8.0520e-01],\n","          [4.3899e-01, 9.8541e-01, 5.0494e-01,  ..., 6.0182e-01,\n","           6.8910e-01, 3.1128e-01]],\n","\n","         [[6.0894e-01, 3.4409e-01, 5.2079e-01,  ..., 6.1090e-01,\n","           3.5019e-01, 3.2065e-01],\n","          [4.9481e-01, 5.0189e-01, 9.6844e-01,  ..., 6.1987e-01,\n","           6.9516e-01, 8.8881e-01],\n","          [2.1284e-01, 2.8494e-02, 3.6887e-01,  ..., 1.6206e-01,\n","           4.7571e-01, 5.7979e-01],\n","          ...,\n","          [5.5639e-01, 5.2714e-01, 6.2604e-01,  ..., 8.8172e-01,\n","           8.5955e-01, 9.2734e-01],\n","          [6.8814e-01, 6.2632e-01, 1.4052e-01,  ..., 6.0703e-01,\n","           3.3528e-02, 5.0131e-01],\n","          [4.0892e-01, 3.4010e-01, 7.9519e-01,  ..., 7.0128e-01,\n","           9.5734e-01, 4.5676e-01]]],\n","\n","\n","        [[[4.9561e-01, 2.8662e-01, 5.9490e-01,  ..., 5.7083e-02,\n","           9.0273e-01, 8.0570e-01],\n","          [8.8045e-01, 1.8200e-01, 4.7112e-01,  ..., 1.5417e-01,\n","           1.3491e-01, 1.3473e-01],\n","          [5.9291e-01, 4.7053e-01, 6.8426e-01,  ..., 6.8675e-01,\n","           8.4332e-01, 2.3390e-01],\n","          ...,\n","          [2.8015e-01, 1.7019e-01, 3.6208e-01,  ..., 1.4734e-02,\n","           8.9297e-01, 3.4530e-01],\n","          [4.5583e-01, 7.7714e-01, 6.6336e-01,  ..., 7.7752e-01,\n","           2.1190e-01, 5.5715e-01],\n","          [1.9549e-01, 6.5776e-01, 9.2677e-01,  ..., 1.2808e-01,\n","           2.7393e-01, 2.9505e-01]],\n","\n","         [[1.5776e-01, 7.1291e-01, 1.2099e-02,  ..., 4.8975e-01,\n","           1.2293e-01, 4.5086e-01],\n","          [8.6703e-01, 6.5977e-01, 6.0301e-03,  ..., 9.0264e-01,\n","           2.4513e-02, 4.9308e-01],\n","          [9.0034e-01, 1.9812e-01, 9.1215e-01,  ..., 3.7212e-01,\n","           7.2806e-01, 9.8805e-01],\n","          ...,\n","          [6.7807e-01, 3.3760e-02, 6.2300e-01,  ..., 8.6056e-01,\n","           8.5739e-02, 7.4025e-01],\n","          [5.4209e-01, 9.4888e-01, 6.7696e-01,  ..., 8.9683e-01,\n","           4.2825e-01, 9.2886e-01],\n","          [7.8763e-01, 6.4442e-01, 5.4573e-01,  ..., 9.6224e-01,\n","           1.7602e-01, 1.2590e-01]],\n","\n","         [[6.2990e-01, 2.1880e-01, 7.9149e-01,  ..., 2.9565e-01,\n","           8.6552e-01, 7.1439e-01],\n","          [4.4578e-01, 3.0569e-01, 8.1539e-04,  ..., 9.9310e-01,\n","           9.0769e-01, 8.7411e-01],\n","          [8.4862e-01, 3.7568e-01, 9.8540e-01,  ..., 4.9328e-01,\n","           9.9346e-01, 6.8102e-01],\n","          ...,\n","          [8.8605e-01, 4.3308e-01, 2.8039e-01,  ..., 1.6633e-01,\n","           7.7456e-02, 8.0621e-01],\n","          [4.2229e-01, 7.3393e-02, 6.9465e-01,  ..., 6.4368e-02,\n","           8.3278e-01, 3.4472e-01],\n","          [5.5703e-02, 6.3570e-01, 9.8615e-01,  ..., 5.4957e-01,\n","           3.7989e-01, 8.6765e-01]]],\n","\n","\n","        [[[7.9578e-01, 5.5778e-01, 6.5854e-01,  ..., 8.2867e-01,\n","           2.5227e-01, 8.4984e-01],\n","          [7.7986e-01, 2.1057e-01, 3.5926e-01,  ..., 6.6324e-01,\n","           6.0836e-02, 1.3269e-01],\n","          [7.8021e-01, 9.9100e-01, 7.2580e-01,  ..., 4.2310e-01,\n","           7.5929e-01, 3.0662e-01],\n","          ...,\n","          [4.0603e-01, 9.9178e-01, 4.8216e-01,  ..., 7.3650e-01,\n","           1.6485e-01, 7.1256e-01],\n","          [8.9920e-02, 5.4713e-01, 4.7309e-01,  ..., 1.5384e-01,\n","           4.8326e-01, 1.8128e-01],\n","          [9.0912e-01, 8.3404e-01, 9.8432e-01,  ..., 2.2537e-01,\n","           3.9287e-01, 1.1804e-01]],\n","\n","         [[6.2723e-01, 4.8453e-01, 2.4188e-01,  ..., 4.7502e-01,\n","           9.0676e-01, 4.0198e-01],\n","          [6.0933e-01, 6.7791e-01, 8.8412e-01,  ..., 7.0123e-01,\n","           4.0368e-01, 9.1471e-01],\n","          [8.4158e-01, 6.6597e-01, 3.0219e-01,  ..., 7.3153e-01,\n","           1.9228e-01, 5.1587e-01],\n","          ...,\n","          [7.3423e-01, 8.9334e-01, 3.2219e-01,  ..., 6.8090e-01,\n","           7.2535e-01, 3.4990e-01],\n","          [4.5308e-01, 5.8463e-01, 2.9438e-01,  ..., 7.0382e-01,\n","           5.6041e-01, 7.3303e-01],\n","          [2.6775e-01, 2.8487e-01, 9.8531e-01,  ..., 2.6716e-01,\n","           9.0273e-01, 8.8887e-01]],\n","\n","         [[8.2844e-01, 1.6874e-01, 7.0952e-01,  ..., 5.9514e-01,\n","           2.2284e-01, 9.0036e-01],\n","          [9.5395e-01, 2.6618e-01, 8.1631e-01,  ..., 7.6539e-01,\n","           8.9330e-01, 4.1351e-02],\n","          [8.3565e-01, 1.4059e-01, 1.3431e-01,  ..., 1.6148e-01,\n","           2.0181e-02, 9.1312e-01],\n","          ...,\n","          [6.3439e-01, 6.8488e-01, 2.0109e-01,  ..., 7.3168e-01,\n","           3.6922e-01, 4.6774e-02],\n","          [6.0090e-02, 8.9017e-01, 3.5138e-01,  ..., 8.8842e-02,\n","           3.9481e-01, 4.5543e-01],\n","          [4.3649e-02, 8.5134e-01, 6.6733e-01,  ..., 6.5944e-01,\n","           7.4419e-01, 9.4601e-01]]]])\n","torch.Size([3, 3, 28, 28])\n"]}],"source":["input_image = torch.rand(3,28,28)\n","print(input_image)\n","print(input_image.size())"]},{"cell_type":"markdown","metadata":{"id":"22v6vyICxvUi"},"source":["#### `nn.Flatten`\n","\n","[`nn.Flatten`](<https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html>) 계층은\n","각 28x28의 2D 이미지를 784 픽셀 값을 갖는 1차원 배열로 변환한다. dim=0의 미니배치 차원은 유지된다.\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"nTOKML8WxvUi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663898553845,"user_tz":-540,"elapsed":2,"user":{"displayName":"유태종","userId":"14183084913974218146"}},"outputId":"581c422f-8aaa-4404-f89b-9fe43ab1b6ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 2352])\n"]}],"source":["flatten = nn.Flatten()\n","flat_image = flatten(input_image)\n","print(flat_image.size()) # First dimension is treated as batch"]},{"cell_type":"markdown","metadata":{"id":"OvDo6_A0xvUj"},"source":["#### `nn.Linear`\n","\n","[선형 계층](<https://pytorch.org/docs/stable/generated/torch.nn.Linear.html>)은 저장된 가중치(weight)와\n","편향(bias)을 사용하여 입력에 선형 변환(linear transformation)을 적용하는 모듈이다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpudx80BxvUj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663890464174,"user_tz":-540,"elapsed":252,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"f7e16daa-52f8-40d7-af8e-0967e2b1fc01"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 20])\n","tensor([[ 0.0723,  0.2944,  0.0688, -0.0080, -0.1988, -0.1473,  0.0402, -0.1625,\n","          0.0051,  0.3092, -0.2408, -0.0197, -0.4539, -0.6212, -0.3582, -0.2164,\n","         -0.1515,  0.2352, -0.6302,  0.4274],\n","        [-0.1705,  0.1423,  0.0308, -0.5483, -0.1650, -0.0633, -0.4033, -0.1392,\n","          0.4359,  0.2693, -0.1483, -0.0269, -0.4287, -0.5644, -0.3774, -0.2523,\n","          0.2513, -0.0018, -0.3849,  0.3450],\n","        [-0.0281,  0.2736,  0.0202, -0.1368, -0.2337, -0.2621, -0.2145, -0.4218,\n","          0.3157,  0.4130, -0.2214,  0.2861, -0.3192, -0.4156, -0.4520,  0.1149,\n","         -0.2612,  0.0755, -0.5630,  0.6957]], grad_fn=<AddmmBackward0>)\n"]}],"source":["layer1 = nn.Linear(in_features=28*28, out_features=20)\n","hidden1 = layer1(flat_image)\n","print(hidden1.size())\n","print(hidden1)"]},{"cell_type":"markdown","metadata":{"id":"cLbZWupgxvUj"},"source":["#### `nn.ReLU`\n","\n","비선형 활성화(activation)는 모델의 입력과 출력 사이에 비선형적인 복잡한 관계(mapping)를 만든다.\n","비선형 활성화는 선형 변환 후에 적용되어 *비선형성(nonlinearity)* 을 도입하고, 신경망이 다양한 현상을 학습할 수 있도록 돕는다.\n","\n","이 모델에서는 [`nn.ReLU`](<https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html>)를 사용하지만, 다양한 다른 활성화 함수를 사용할 수도 있다. \n","\n","**Note:** $ReLu(x) = \\max(0, x)$이다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mopVyRYDxvUk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663890468975,"user_tz":-540,"elapsed":263,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"ac42e4fd-7d39-4a2f-a303-884ad183c17b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Before ReLU: tensor([[ 0.0723,  0.2944,  0.0688, -0.0080, -0.1988, -0.1473,  0.0402, -0.1625,\n","          0.0051,  0.3092, -0.2408, -0.0197, -0.4539, -0.6212, -0.3582, -0.2164,\n","         -0.1515,  0.2352, -0.6302,  0.4274],\n","        [-0.1705,  0.1423,  0.0308, -0.5483, -0.1650, -0.0633, -0.4033, -0.1392,\n","          0.4359,  0.2693, -0.1483, -0.0269, -0.4287, -0.5644, -0.3774, -0.2523,\n","          0.2513, -0.0018, -0.3849,  0.3450],\n","        [-0.0281,  0.2736,  0.0202, -0.1368, -0.2337, -0.2621, -0.2145, -0.4218,\n","          0.3157,  0.4130, -0.2214,  0.2861, -0.3192, -0.4156, -0.4520,  0.1149,\n","         -0.2612,  0.0755, -0.5630,  0.6957]], grad_fn=<AddmmBackward0>)\n","\n","\n","After ReLU: tensor([[0.0723, 0.2944, 0.0688, 0.0000, 0.0000, 0.0000, 0.0402, 0.0000, 0.0051,\n","         0.3092, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2352,\n","         0.0000, 0.4274],\n","        [0.0000, 0.1423, 0.0308, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4359,\n","         0.2693, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2513, 0.0000,\n","         0.0000, 0.3450],\n","        [0.0000, 0.2736, 0.0202, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3157,\n","         0.4130, 0.0000, 0.2861, 0.0000, 0.0000, 0.0000, 0.1149, 0.0000, 0.0755,\n","         0.0000, 0.6957]], grad_fn=<ReluBackward0>)\n"]}],"source":["print(f\"Before ReLU: {hidden1}\\n\\n\")\n","hidden1 = nn.ReLU()(hidden1)\n","print(f\"After ReLU: {hidden1}\")"]},{"cell_type":"markdown","metadata":{"id":"hHQzZfQqxvUk"},"source":["#### `nn.Sequential`\n","\n","[`nn.Sequential`](<https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html>)은 순서를 갖는\n","모듈의 컨테이너이다. 데이터는 모듈들을 나열된 순서대로 통과한다. 순차 컨테이너(sequential container)를 사용하여 아래의 ``seq_modules``와 같은 신경망을 빠르게 만들 수 있다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wk7N-sv8xvUk"},"outputs":[],"source":["seq_modules = nn.Sequential(\n","    flatten,\n","    layer1,\n","    nn.ReLU(),\n","    nn.Linear(20, 10)\n",")\n","input_image = torch.rand(3,28,28)\n","logits = seq_modules(input_image)"]},{"cell_type":"markdown","metadata":{"id":"m_jYETo_xvUl"},"source":["#### `nn.Softmax`\n","\n","신경망의 마지막 선형 계층은 [`nn.Softmax`](<https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html>) 모듈에 전달될\n","[-\\infty, \\infty] 범위의 원시 값(raw value)인 `logits`를 반환한다. `nn.Softmax` 계층은 logits는 모델의 각 분류(class)에 대한 예측 확률을 나타내도록\n","[0, 1] 범위로 비례하여 조정(scale)한다. ``dim`` 매개변수는 값의 합이 1이 되는 차원을 나타낸다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MezKS9-bxvUl"},"outputs":[],"source":["softmax = nn.Softmax(dim=1)\n","pred_probab = softmax(logits)"]},{"cell_type":"markdown","source":["**Note:** `SoftMax`함수 $\\sigma : R^K \\longrightarrow (0, 1)^K$의 정의: $\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$"],"metadata":{"id":"QXRDL7r1dr0q"}},{"cell_type":"markdown","metadata":{"id":"_czY6AClxvUl"},"source":["모델 매개변수\n","------------------------------------------------------------------------------------------\n","\n","신경망에서 많은 계층들은 *매개변수화(parameterize)*되어 있다. 즉, 학습 중에 최적화되는 가중치(weight)와 편향(bias)을 가진다. ``nn.Module``을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적(track)되며, 모델의 ``parameters()`` 및\n","``named_parameters()`` 메소드로 모든 매개변수에 접근할 수 있게 된다.\n","\n","이 예제에서는 각 매개변수들을 순회하며(iterate), 매개변수의 크기와 값을 출력한다.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JsRgYxQdxvUl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663890507819,"user_tz":-540,"elapsed":240,"user":{"displayName":"권오흠","userId":"05475008821310211864"}},"outputId":"4e2031c5-b828-4405-91d3-0c06ec643379"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model structure: NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","\n","\n","Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0084, -0.0223, -0.0094,  ...,  0.0350, -0.0234, -0.0309],\n","        [ 0.0003, -0.0201, -0.0074,  ..., -0.0274, -0.0022,  0.0242]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0234,  0.0290], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0291, -0.0322,  0.0107,  ...,  0.0326,  0.0043, -0.0377],\n","        [-0.0336,  0.0261,  0.0130,  ...,  0.0281,  0.0441,  0.0378]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0211, -0.0100], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0383, -0.0207, -0.0092,  ..., -0.0336,  0.0405,  0.0211],\n","        [-0.0391, -0.0320,  0.0403,  ..., -0.0117, -0.0157, -0.0069]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0288,  0.0344], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n"]}],"source":["print(f\"Model structure: {model}\\n\\n\")\n","\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"HTbmC4EaxvUl"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kdVeExgOxvUm"},"source":["더 읽어보기\n","------------------------------------------------------------------------------------------\n","- [`torch.nn API`](<https://pytorch.org/docs/stable/nn.html>)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[{"file_id":"1Z7nDvIb3DNHrAhkaji0IEKgwC5sVMHYj","timestamp":1663897504357}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}