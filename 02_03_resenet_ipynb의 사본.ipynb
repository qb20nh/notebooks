{"cells":[{"cell_type":"markdown","metadata":{"id":"R5dbDkx70lCX"},"source":["# Writing `ResNet` from Scratch in PyTorch\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WozRbNY50-1t"},"source":["이 강좌는 [이 블로그](https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/)의 내용을 번역하고 부분적으로 수정한 것이다.\n","\n","Resnet은 Residual Connections의 개념을 도입하여 네트워크가 너무 깊을 경우 네트워크 성능이 저하되는 문제를 해결한 Computer Vision의 주요 혁신중 하나이다.\n","우선 ResNet의 아키텍처와 그 뒤에 숨어있는 직관적인 아이디어를 살펴보는 것으로 시작한다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vzXMRHMm2Shi"},"source":["## Residual Block과 `Resnet`"]},{"cell_type":"markdown","metadata":{"id":"r5s_6pGBiuMe"},"source":["Resnet의 핵심 구성요소는 resudual block이다. 아래 그림이 하나의 residual block을 보여준다."]},{"cell_type":"markdown","metadata":{"id":"KlEwVGZz2VkS"},"source":["\n","\n","\u003cimg src=\"https://raw.githubusercontent.com/ohheum/DS2022/7ef336792c0a4ae3044653a7e020818354656b55/assets/image-9.png\" width=\"600\" height=\"360\"\u003e\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JVvyo-S74fwf"},"source":["위의 그림에서 보이듯이 순차적인 연결 외에 모델의 일부 계층을 건너뛰는 연결(**skipped connection**)이 있다. 건너뛰기 연결이 없을 때 이 모델이 학습해야할 매핑을 `H(x)`라고 한다면 건너뛰기 연결을 추가할 경우 순차 연결 부분이 학습해야할 매핑은 `F(x) = H(x) - x`가 될 것이다. 이 잔여(residual) 매핑  `F(x)`를 학습하는 것이 원래의 매핑 `H(x)`를 학습하는 것보다 쉽다. (극단적인 예로 `H(x)`가 identity mapping이라면 residual mapping F(x)는 zero mapping이다. identity mapping보다는 zero mapping이 학습하기 쉬울 것이다.)\n","\n","아래는 34 레이어 ResNet의 아키텍처입니다."]},{"cell_type":"markdown","metadata":{"id":"tjNFuA564Y4e"},"source":["\u003cimg src=\"https://raw.githubusercontent.com/ohheum/DS2022/7ef336792c0a4ae3044653a7e020818354656b55/assets/image-10.png\" width=\"800\" height=\"1800\"\u003e"]},{"cell_type":"markdown","metadata":{"id":"lwXbI5YL4lY1"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"5UCTxdK34nQm"},"source":["CIFAR-10 데이터 세트를 사용한다. CIFAR-10 데이터 세트는 10개 클래스의 60000개의 32x32 컬러 이미지로 구성되며 클래스당 6000개의 이미지가 있다. 50000개의 훈련 이미지와 10000개의 테스트 이미지가 있다.\n","\n","데이터 세트는 각각 10000개의 이미지가 있는 5개의 훈련 배치와 1개의 테스트 배치로 나뉜다. 테스트 배치에는 각 클래스에서 무작위로 선택된 정확히 1000개의 이미지가 포함된다. 학습 배치에는 나머지 이미지가 무작위 순서로 포함되지만 일부 학습 배치에는 한 클래스의 이미지가 다른 클래스보다 더 많을 수 있다. "]},{"cell_type":"markdown","metadata":{"id":"jWr1MnUY4uqu"},"source":["\u003cimg src=\"https://pytorch.org/tutorials/_images/cifar10.png\" width=\"600\" height=\"420\"\u003e"]},{"cell_type":"markdown","metadata":{"id":"pd1kloIX48Qm"},"source":["## Importing the Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1271,"status":"ok","timestamp":1664868368738,"user":{"displayName":"유태종","userId":"14183084913974218146"},"user_tz":-540},"id":"3x85MEgYZcvr","outputId":"ad9c1f80-5a47-49c5-eb2c-d0f225e42fe9"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets\n","from torchvision import transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"M-phgx7a5AMU"},"source":["## Loading the Dataset"]},{"cell_type":"markdown","metadata":{"id":"xjTM5TIC5DsB"},"source":["토치비전 라이브러리를 사용하여 데이터 세트를 로드한다."]},{"cell_type":"markdown","metadata":{"id":"VyT0X42N5OVA"},"source":["* 아래의의 `data_loader` 함수는 트레이닝 데이터와 테스트 데이터에 대한 `DataLoader`를 생성하여 반환한다. \n","* 데이터 세트의 각 채널(빨간색, 녹색 및 파란색)의 평균 및 표준 편차로 정규화를 수행한다.\n","* 데이터 로더를 사용하면 데이터를 일괄적으로 반복할 수 있으며 데이터는 반복하는 동안 로드되며 시작 시 한 번에 모두 RAM에 로드되지는 않는다. 이것은 대규모 데이터 세트를 처리하는 경우 매우 유용하다.\n","* 매개변수 `test=False`인 경우 트레이닝 분할을, `test=True`인 경우 테스트 분할을 로드한다. train의 경우 분할은 무작위로 train과 validation set(0.9:0.1)으로 나뉜다."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4349,"status":"ok","timestamp":1664868819999,"user":{"displayName":"유태종","userId":"14183084913974218146"},"user_tz":-540},"id":"PfiQ5edcZvVi","outputId":"581e7e50-e6fb-438d-da81-30900643a175"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["def data_loader(data_dir,\n","                batch_size,\n","                random_seed=42,\n","                valid_size=0.1,\n","                shuffle=True,\n","                test=False):\n","  \n","    normalize = transforms.Normalize( # empirical parameter, probably mean and stddev of whole dataset\n","        mean=[0.4914, 0.4822, 0.4465],\n","        std=[0.2023, 0.1994, 0.2010],\n","    )\n","\n","    # define transforms\n","    transform = transforms.Compose([ # function composition\n","            transforms.Resize((224,224)),\n","            transforms.ToTensor(),\n","            normalize,\n","    ])\n","\n","    if test:\n","        dataset = datasets.CIFAR10(\n","          root=data_dir, train=False,\n","          download=True, transform=transform,\n","        )\n","\n","        data_loader = torch.utils.data.DataLoader(\n","            dataset, batch_size=batch_size, shuffle=shuffle\n","        )\n","\n","        return data_loader\n","\n","    # load the dataset\n","    train_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=transform,\n","    )\n","\n","    valid_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=transform,\n","    )\n","\n","    num_train = len(train_dataset)\n","    indices = list(range(num_train)) # list of [0, ..., num_train-1]\n","    split = int(np.floor(valid_size * num_train))\n","\n","    if shuffle:\n","        np.random.seed(42)\n","        np.random.shuffle(indices)\n","\n","    train_idx, valid_idx = indices[split:], indices[:split]\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, sampler=train_sampler)\n"," \n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n","\n","    return (train_loader, valid_loader)\n","\n","\n","# CIFAR10 dataset \n","train_loader, valid_loader = data_loader(data_dir='./data',\n","                                         batch_size=64)\n","\n","test_loader = data_loader(data_dir='./data',\n","                              batch_size=64,\n","                              test=True)"]},{"cell_type":"markdown","metadata":{"id":"Ur-7NAIm5gDW"},"source":["## How models work in PyTorch"]},{"cell_type":"markdown","metadata":{"id":"q6u8780k5jc2"},"source":[" ResNet에는 PyTorch가 제공하는 다양한 유형의 레이어가 사용된다.\n","\n","* nn.Conv2d: 커널 크기와 함께 입력 및 출력 채널의 수를 인수로 받아들이는 컨볼루션 계층. \n","* nn.BatchNorm2d: 컨볼루션 레이어의 출력에 일괄 정규화를 적용, 각 레이어 정규화 하는데 그 정규화 파라메터도 최적화\n","* nn.ReLU: 네트워크의 다양한 출력에 적용되는 활성화 함수\n","* nn.MaxPool2d : 최대 풀링을 적용\n","* nn.Dropout: 주어진 확률로 출력에 드롭아웃을 적용 (prob 을 줘서 레이어 각 아웃풋을 prob확률로 0으로 강제), overfit 방지\n","* nn.Linear: 완전히 연결된 레이어\n","* nn.Sequential: 여러 계층을 결합하는데 사용됨"]},{"cell_type":"markdown","metadata":{"id":"EqD9C1Qe5s3m"},"source":["## Residual Block"]},{"cell_type":"markdown","metadata":{"id":"OYFue1Gy5vJ2"},"source":["먼저 네트워크 전체에서 재사용할 수 있는 ResidualBlock을 정의한다. "]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":486,"status":"ok","timestamp":1664872443799,"user":{"displayName":"유태종","userId":"14183084913974218146"},"user_tz":-540},"id":"8HZ8Tb00ZzCJ"},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n","                        nn.BatchNorm2d(out_channels),\n","                        nn.ReLU())\n","        self.conv2 = nn.Sequential(\n","                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n","                        nn.BatchNorm2d(out_channels))\n","        self.downsample = downsample\n","        self.relu = nn.ReLU()\n","        self.out_channels = out_channels\n","        \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        if self.downsample: # stride에 따라 residual과 x의 사이즈 일치시키기 위한 operation\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"dMABgdVS51t9"},"source":["## Resnet"]},{"cell_type":"markdown","metadata":{"id":"P4rV_1Og53Tu"},"source":["이제 ResidualBlock을 만들었으므로 ResNet을 빌드할 수 있다.\n","\n","아키텍처에는 각각 3, 3, 6, 3개의 레이어를 포함하는 3개의 블록이 있다. 이 블록을 만들기 위해 도우미 함수 _make_layer를 만든다. 이 기능은 Residual Block과 함께 레이어를 하나씩 추가한다. 블록 다음에 평균 풀링과 최종 선형 레이어를 추가한다."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":594,"status":"ok","timestamp":1664872654685,"user":{"displayName":"유태종","userId":"14183084913974218146"},"user_tz":-540},"id":"msVMW6gxZ4ap"},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(self, block, layers, num_classes = 10):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n","                        nn.BatchNorm2d(64),\n","                        nn.ReLU())\n","        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n","        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n","        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.fc = nn.Linear(512, num_classes)\n","        \n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes:\n","            \n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n","                nn.BatchNorm2d(planes),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","    \n","    \n","    def forward(self, x):     # x.shape=(3,224,224)\n","        x = self.conv1(x)     # (112, 112)\n","        x = self.maxpool(x)   # (56, 56)\n","        x = self.layer0(x)    # (56, 56)\n","        x = self.layer1(x)    # (28, 28)\n","        x = self.layer2(x)    # (14, 14)\n","        x = self.layer3(x)    # (7, 7)\n","\n","        x = self.avgpool(x)   # (1,1)\n","        x = x.view(x.size(0), -1)   # 512 # flatten\n","        x = self.fc(x)        \n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"bIzlULci582f"},"source":["## Setting Hyperparameters"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11441,"status":"ok","timestamp":1664872673653,"user":{"displayName":"유태종","userId":"14183084913974218146"},"user_tz":-540},"id":"QqURongpZ6e7","outputId":"11471a9a-60c3-458c-8fa5-4fb856c50090"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,472\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,928\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,928\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","    ResidualBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,928\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,928\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","    ResidualBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19           [-1, 64, 56, 56]          36,928\n","      BatchNorm2d-20           [-1, 64, 56, 56]             128\n","             ReLU-21           [-1, 64, 56, 56]               0\n","           Conv2d-22           [-1, 64, 56, 56]          36,928\n","      BatchNorm2d-23           [-1, 64, 56, 56]             128\n","             ReLU-24           [-1, 64, 56, 56]               0\n","    ResidualBlock-25           [-1, 64, 56, 56]               0\n","           Conv2d-26          [-1, 128, 28, 28]          73,856\n","      BatchNorm2d-27          [-1, 128, 28, 28]             256\n","             ReLU-28          [-1, 128, 28, 28]               0\n","           Conv2d-29          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-30          [-1, 128, 28, 28]             256\n","           Conv2d-31          [-1, 128, 28, 28]           8,320\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","    ResidualBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-36          [-1, 128, 28, 28]             256\n","             ReLU-37          [-1, 128, 28, 28]               0\n","           Conv2d-38          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-39          [-1, 128, 28, 28]             256\n","             ReLU-40          [-1, 128, 28, 28]               0\n","    ResidualBlock-41          [-1, 128, 28, 28]               0\n","           Conv2d-42          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-43          [-1, 128, 28, 28]             256\n","             ReLU-44          [-1, 128, 28, 28]               0\n","           Conv2d-45          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-46          [-1, 128, 28, 28]             256\n","             ReLU-47          [-1, 128, 28, 28]               0\n","    ResidualBlock-48          [-1, 128, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,584\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","    ResidualBlock-55          [-1, 128, 28, 28]               0\n","           Conv2d-56          [-1, 256, 14, 14]         295,168\n","      BatchNorm2d-57          [-1, 256, 14, 14]             512\n","             ReLU-58          [-1, 256, 14, 14]               0\n","           Conv2d-59          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-60          [-1, 256, 14, 14]             512\n","           Conv2d-61          [-1, 256, 14, 14]          33,024\n","      BatchNorm2d-62          [-1, 256, 14, 14]             512\n","             ReLU-63          [-1, 256, 14, 14]               0\n","    ResidualBlock-64          [-1, 256, 14, 14]               0\n","           Conv2d-65          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-66          [-1, 256, 14, 14]             512\n","             ReLU-67          [-1, 256, 14, 14]               0\n","           Conv2d-68          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-69          [-1, 256, 14, 14]             512\n","             ReLU-70          [-1, 256, 14, 14]               0\n","    ResidualBlock-71          [-1, 256, 14, 14]               0\n","           Conv2d-72          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-73          [-1, 256, 14, 14]             512\n","             ReLU-74          [-1, 256, 14, 14]               0\n","           Conv2d-75          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-76          [-1, 256, 14, 14]             512\n","             ReLU-77          [-1, 256, 14, 14]               0\n","    ResidualBlock-78          [-1, 256, 14, 14]               0\n","           Conv2d-79          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-80          [-1, 256, 14, 14]             512\n","             ReLU-81          [-1, 256, 14, 14]               0\n","           Conv2d-82          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","    ResidualBlock-85          [-1, 256, 14, 14]               0\n","           Conv2d-86          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-87          [-1, 256, 14, 14]             512\n","             ReLU-88          [-1, 256, 14, 14]               0\n","           Conv2d-89          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-90          [-1, 256, 14, 14]             512\n","             ReLU-91          [-1, 256, 14, 14]               0\n","    ResidualBlock-92          [-1, 256, 14, 14]               0\n","           Conv2d-93          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-94          [-1, 256, 14, 14]             512\n","             ReLU-95          [-1, 256, 14, 14]               0\n","           Conv2d-96          [-1, 256, 14, 14]         590,080\n","      BatchNorm2d-97          [-1, 256, 14, 14]             512\n","             ReLU-98          [-1, 256, 14, 14]               0\n","    ResidualBlock-99          [-1, 256, 14, 14]               0\n","          Conv2d-100            [-1, 512, 7, 7]       1,180,160\n","     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n","            ReLU-102            [-1, 512, 7, 7]               0\n","          Conv2d-103            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n","          Conv2d-105            [-1, 512, 7, 7]         131,584\n","     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n","            ReLU-107            [-1, 512, 7, 7]               0\n","   ResidualBlock-108            [-1, 512, 7, 7]               0\n","          Conv2d-109            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n","            ReLU-111            [-1, 512, 7, 7]               0\n","          Conv2d-112            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n","            ReLU-114            [-1, 512, 7, 7]               0\n","   ResidualBlock-115            [-1, 512, 7, 7]               0\n","          Conv2d-116            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n","            ReLU-118            [-1, 512, 7, 7]               0\n","          Conv2d-119            [-1, 512, 7, 7]       2,359,808\n","     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n","            ReLU-121            [-1, 512, 7, 7]               0\n","   ResidualBlock-122            [-1, 512, 7, 7]               0\n","       AvgPool2d-123            [-1, 512, 1, 1]               0\n","          Linear-124                   [-1, 10]           5,130\n","================================================================\n","Total params: 21,298,314\n","Trainable params: 21,298,314\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 96.28\n","Params size (MB): 81.25\n","Estimated Total Size (MB): 178.10\n","----------------------------------------------------------------\n","None\n"]}],"source":["num_classes = 10\n","num_epochs = 20\n","batch_size = 16\n","learning_rate = 0.01\n","\n","model = ResNet(ResidualBlock, [3, 4, 6, 3]).to(device)\n","\n","from torchsummary import summary\n","print(summary(model, (3, 224, 224)))\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)  \n","\n","# Train the model\n","total_step = len(train_loader)"]},{"cell_type":"markdown","metadata":{"id":"KwfVZC536C8-"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Wr-1vzX5Z9XI"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/20], Loss: 1.2589\n","Accuracy of the network on the 5000 validation images: 56.68 %\n","Epoch [2/20], Loss: 0.4178\n","Accuracy of the network on the 5000 validation images: 73.86 %\n","Epoch [3/20], Loss: 0.4106\n","Accuracy of the network on the 5000 validation images: 78.14 %\n","Epoch [4/20], Loss: 0.2229\n","Accuracy of the network on the 5000 validation images: 79.06 %\n","Epoch [5/20], Loss: 1.0332\n","Accuracy of the network on the 5000 validation images: 81.64 %\n"]}],"source":["import gc\n","total_step = len(train_loader)\n","\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):  \n","        # Move tensors to the configured device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        del images, labels, outputs\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    print ('Epoch [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, loss.item()))\n","            \n","    # Validation\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in valid_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            del images, labels, outputs\n","    \n","        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) "]},{"cell_type":"markdown","metadata":{"id":"6DdUOW0j6QIg"},"source":["코드의 출력을 보면 매 에포크마다 검증(validation) 세트의 정확도가 증가하고 손실이 감소함에 따라 모델이 학습하고 있음을 알 수 있다. "]},{"cell_type":"markdown","metadata":{"id":"yyaey-7C6WG1"},"source":["## Testing"]},{"cell_type":"markdown","metadata":{"id":"scU8tvDD6XsU"},"source":["테스트를 위해 유효성 검사와 정확히 동일한 코드를 사용하지만 test_loader를 사용한다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32101,"status":"ok","timestamp":1663058727534,"user":{"displayName":"권오흠","userId":"05475008821310211864"},"user_tz":-540},"id":"Ve5OoeR6aKx5","outputId":"465344b4-780f-4b2d-cc66-993fd83328ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 10000 test images: 83.93 %\n"]}],"source":["with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        del images, labels, outputs\n","\n","    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))   "]},{"cell_type":"markdown","metadata":{"id":"2JULaEu1g01L"},"source":["\n","위의 코드를 사용하고 10개의 에포크 동안 모델을 훈련하여 테스트 세트에서 82.87%의 정확도를 달성할 수 있었다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y8x0XSKjqAa_"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"","provenance":[{"file_id":"1b5zXzk3Ye8AXzgopzkudZJz9PqCSZEIU","timestamp":1664504411818}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}