{"cells":[{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"xWWYqeT1A6Jb","tags":[]},"source":["# 프로그래밍 과제 1"]},{"cell_type":"markdown","metadata":{"id":"bofyTRLjBJhq"},"source":["**이 노트북을 완성하여 LMS로 제출한다. 작성한 코드의 실행결과를 지우지 말고 보존한 상태로 제출해야 한다.**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ho7QCo4hPh7q"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":3,"metadata":{"deletable":false,"editable":false,"id":"i03cL5y4A6Jh","tags":[]},"outputs":[],"source":["import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"xkdN2JZQXT5y","tags":[]},"source":["10종류의 음식에 대해서 각각 1,000장의 이미지로 구성된 [데이터셋](https://drive.google.com/file/d/1rZ9DX4cDW7g0OGeFgkFKFzA_jZ1bzS93/view?usp=sharing)을 다운로드 받는다. 이 데이터셋은 torchvision이 제공하는 Food101 데이터셋에서 10종류의 음식만 선택해서 만든 것이다. 다운로드한 파일 `food10.zip`의 압축을 해제하면 `food10` 디렉토리의 내부에 두 개의 디렉토리 `train`과 `test`가 있고 각각에는 8,000과 2,000장의 음식 이미지가 들어있다. 이미지의 크기는 균일하지 않다. \n","\n","모든 이미지 파일의 이름은 0-9 사이의의 정수로 시작된다. 그 정수가 음식의 종류를 표시한다. 다음의 리스트 `classes`는 0-9번 까지의 음식 종류의 명칭이다. 예를 들어 `5_2871066.jpg`는 5로 시작하므로 나초(nachos)이다."]},{"cell_type":"markdown","metadata":{"id":"b27L0IkUULZR"},"source":["**주의:** 압축해제한 디렉토리 `food10`과 하위 디렉토리 `train` 및 `test`에 `.DS_Store`라는 이름의 숨김 파일이 있을 수 있다. 이 파일들은 모두 찾아내어 삭제해야 한다."]},{"cell_type":"code","execution_count":4,"metadata":{"deletable":false,"editable":false,"id":"DC2YS6O0eFrQ","tags":[]},"outputs":[],"source":["classes = ['donuts', 'french_fries', 'gyoza', 'hamburger', 'ice_cream', 'nachos', 'pizza', 'ramen', 'risotto', 'sushi']"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"YcL3NQ46YTrA","tags":[]},"source":["Colab을 사용할 경우에는 `food10` 디렉토리를 자신의 Google Drive의 적절한 위치에 저장한다. PC에서 실행할할 경우에는 PC의 적절한 위치에 저장한다."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"v5arEVBJZP0c","tags":[]},"source":["Colab을 사용할 경우 먼저 자신의 Google Drive를 다음과 같이 마운트한다. 이 작업은 로컬 PC에서는 불필요하다."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"deletable":false,"editable":false,"executionInfo":{"elapsed":28256,"status":"ok","timestamp":1664409372948,"user":{"displayName":"권오흠","userId":"05475008821310211864"},"user_tz":-540},"id":"x3TucI2hQMEA","outputId":"e380538e-bd3a-4750-998a-59d918ff4e08","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["['download', 'food10.zip', 'food10', 'drive-download-20220927T080006Z-001', '.ipynb_checkpoints', 'data', 'datasets', '__MACOSX']\n","/notebooks/,\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')\n","\n","import os\n","\n","dir = os.listdir('.')\n","abspath = os.path.abspath(',')\n","\n","print(dir)\n","print(abspath)"]},{"cell_type":"markdown","metadata":{},"source":["## Downloading dataset from Google Drive"]},{"cell_type":"markdown","metadata":{},"source":["Install `gdown` package"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.5.1)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.7.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.28.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.64.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.1.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.10)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2019.11.28)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install gdown"]},{"cell_type":"markdown","metadata":{},"source":["Use cached download and extract after"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Computing MD5: food10.zip\n","MD5 matches: food10.zip\n"]},{"data":{"text/plain":["'food10.zip'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import gdown\n","\n","url = 'https://drive.google.com/uc?id=1rZ9DX4cDW7g0OGeFgkFKFzA_jZ1bzS93'\n","output = 'food10.zip'\n","md5 = '4490d5d6a16cd56870c411a489f80b3e'\n","\n","gdown.cached_download(url, output, md5=md5, quiet=False, postprocess=gdown.extractall)"]},{"cell_type":"markdown","metadata":{},"source":["Calculate downloaded file's checksum for later use"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4490d5d6a16cd56870c411a489f80b3e  food10.zip\n"]}],"source":["!md5sum food10.zip"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"fNX0N-1HZaLF","tags":[]},"source":["데이터 디렉토리의 경로를 다음과 같이 설정한다. 각자 자신의 환경에 맞게 설정하면 된다."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"NvNB-4JXQXj4"},"outputs":[],"source":["# data_root = '/Users/taejongyoo/Library/CloudStorage/OneDrive-개인/부경대/강의/2022-2/딥러닝2/notebooks/datasets/food10' # local\n","data_root = '/notebooks/food10' # remote"]},{"cell_type":"markdown","metadata":{"id":"aANdlDuwWCGe"},"source":["_________________________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"OmcOOn1wVsGO","tags":[]},"source":["**문제 1:** 이미지의 크기를 균일하게 하고, 픽셀값을 적절하게 정규화하며, 또한 이미지와 라벨을 텐서(Tensor)로 변환하기 위한 데이터 전처리가 필요하다. `torchvision.transforms.Compose`를 이용하여 적절한 전처리 절차 `transform`을 정의하라. 이미지는 50*50 크기로 resizing하고, 각 채널의 픽셀값은 적절하게 정규화한다. "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TUKOvhPTQaTw"},"outputs":[],"source":["transform = transforms.Compose([\n","    #  YOUR CODE HERE\n","    transforms.Resize((50, 50)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        (0.5432, 0.4355, 0.3316),\n","        (0.2576, 0.2510, 0.2530),\n","    ),\n","])"]},{"cell_type":"markdown","metadata":{"id":"9Ju6BjZhXoWj"},"source":["_________________________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"0aMsTNwQafWd","tags":[]},"source":["**문제 2:** 데이터셋을 하나의 클래스 `FoodImageDataset`로 정의하라. 이 클래스를 이용하여 데이터셋을 생성할 때 training 데이터셋은 다음과 같이:\n","\n","`trainset = FoodImageDataset(data_root, training=True, transform=transform)`\n","\n","그리고, 테스트 데이터셋은 다음과 같이:\n","\n","`testset = FoodImageDataset(data_root, training=False, transform=transform)`\n","\n","생성할 수 있어야 한다. 즉, 매개변수수 `training`이 `True`인지 `False`인지에 따라서 구분하도록 구현하라."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"e9nH9cOdRFu4"},"outputs":[],"source":["from PIL import Image\n","from torchvision.io import read_image\n","import glob\n","\n","class FoodImageDataset(Dataset):\n","    # YOUR CODE HERE\n","    # creating a custom dataset\n","    # https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n","    def __init__(self, training: bool, transform: torch.nn.Module):\n","        \"\"\"\n","        Initializer function that runs once when creating a new instance of this dataset\n","\n","        :param training: Boolean flag indicating whether this dataset will be used for training or for testing\n","        :type training: bool\n","        :param transform: Transformer module to preprocess the input samples before it is read\n","        :type transform: torch.nn.Module\n","        \"\"\"\n","        self.training = training\n","        self.transform = transform\n","        self._dataset_root = os.path.join(data_root, \"train\" if self.training else \"test\")\n","        self._paths = []\n","\n","    def _load_paths(self, force_reload: bool = True):\n","        # since the data sample hardly changes while using the dataset, and we need to\n","        # keep the ordering of files listed, it is better if we cache the whole file list\n","        if not force_reload or not self._paths:\n","            # list files in the directory; courtesy of https://stackoverflow.com/a/2632251\n","            # and https://stackoverflow.com/a/7099342/4592648\n","            # assume all files in the dataset directory are indeed correct and well-formed \\\n","            # sample and no samples are added and removed during the usage of this dataset\n","            self._paths = [\n","                name\n","                for name in glob.glob(os.path.join(self._dataset_root, '*'))\n","                if os.path.isfile(os.path.join(self._dataset_root, name))\n","            ]\n","\n","    def __len__(self) -> int:\n","        \"\"\"\n","        Returns a number of samples in this dataset.\n","\n","        :return: Number of samples in this dataset\n","        :rtype: int\n","        \"\"\"\n","        self._load_paths()\n","        return len(self._paths)\n","\n","    def _read_image(self, filename: str):\n","        return Image.open(os.path.join(self._dataset_root, filename))\n","\n","    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","        Loads and returns a sample for the given index in this dataset\n","\n","        :param index: Index of the sample to fetch\n","        :type index: int\n","        :return: A sequence of single image sample and its target label\n","        :rtype: tuple[torch.Tensor, torch.Tensor]\n","        \"\"\"\n","        self._load_paths()\n","        abspath = self._paths[index]\n","        filename = os.path.split(abspath)[1]\n","        image = self._read_image(abspath)\n","        # TODO: might be more efficient if we could mark the transforms' determinism and cache the results\n","        if self.transform:\n","            image = self.transform(image)\n","        label = int(filename.split(\"_\")[0])\n","        return image, label\n"]},{"cell_type":"markdown","metadata":{"id":"P47UjjPYaBqm"},"source":["__________________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"RoFYuSRAbgOr","tags":[]},"source":["**문제 3:** 작성한 클래스 `FoodImageDataset`를 이용하여 두 개의 데이터셋 `trainset`, `testset`과 또한 각각에 대한 데이터 로더 `trainloader`, `testloader`를 생성하라. `trainloader`에서는 데이터를 shuffling하고, `testloader`에서는 shuffling하지 않는다. 배치 크기는 32로 한다."]},{"cell_type":"code","execution_count":11,"metadata":{"deletable":false,"editable":false,"id":"jkhIO2WOaLhn","tags":[]},"outputs":[],"source":["batch_size = 32"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"G9VqpfWSZgSR"},"outputs":[],"source":["# 여기에서 trainset, testset, trainloader, testloader를 생성한다.\n","\n","trainset = FoodImageDataset(training=True, transform=transform)\n","testset = FoodImageDataset(training=False, transform=transform)\n","\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate mean and std of dataset\n","\n","From https://gist.github.com/JorritWillaert/2cae1da8cd42226a184f0268c0cb58f8"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def get_mean_and_std(dataloader):\n","    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n","    for data, _ in dataloader:\n","        # Mean over batch, height and width, but not over the channels\n","        channels_sum += torch.mean(data, dim=[0,2,3])\n","        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n","        num_batches += 1\n","\n","    mean = channels_sum / num_batches\n","\n","    # std = sqrt(E[X^2] - (E[X])^2)\n","    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n","\n","    return mean, std"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([0.5432, 0.4355, 0.3316]), tensor([0.2576, 0.2510, 0.2530]))"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["get_mean_and_std(trainloader)"]},{"cell_type":"markdown","metadata":{"id":"NzZU2OEEZ8PT"},"source":["_______________________________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"vj9Mn3o7b4RD","tags":[]},"source":["아래의 함수 `imshow`는 하나의 Tensor 타입의 이미지를 받아서 화면에 디스플레이하는 함수이다. 이 함수는 픽셀 값들이 `-1.0~1.0` 사이의 실수로 정규화되어 있다고 가정하고 있다. "]},{"cell_type":"code","execution_count":14,"metadata":{"deletable":false,"editable":false,"id":"BDlKBc1NbDXi","tags":[]},"outputs":[],"source":["import numpy as np\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"yJUcXNPLcETz","tags":[]},"source":["아래의 코드를 실행하면 하나의 이미지가 디스플레이 되어야 한다. 또한 배치(batch)의 shape과 최대값, 최소값, 평균값 등이 올바른지 확인해보라."]},{"cell_type":"code","execution_count":15,"metadata":{"deletable":false,"editable":false,"id":"uC1BmaPba3N_","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(4)\n","torch.Size([32, 3, 50, 50])\n","torch.Size([32])\n","tensor(2.4249)\n","tensor(-2.0935)\n","tensor(-0.5596)\n"]}],"source":["for img, label in trainloader:\n","    imshow(img[0])\n","    print(label[0])\n","    print(img.shape)\n","    print(label.shape)\n","    print(img[0].max())\n","    print(img[0].min())\n","    print(img[0].mean())\n","    break"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"9jRCrhtSbX6f","tags":[]},"source":["실행할 디바이스를 선택한다."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"deletable":false,"editable":false,"executionInfo":{"elapsed":1095,"status":"ok","timestamp":1664409568339,"user":{"displayName":"권오흠","userId":"05475008821310211864"},"user_tz":-540},"id":"LVZbSTqj9p9b","outputId":"dda927ee-cf0e-4a62-9047-3d35982c9111","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"3h5DuC7bcNLj","tags":[]},"source":["**문제 4:** 3개의 컨볼루션 층을 가진 CNN을 하나의 클래스 Net으로 구현하라. 각각의 컨볼루션 층에서는 순서대로 16, 32, 32개의 크기가 3인 필터를 적용하라. `stride`나 `padding` 등의 나머지 선택사항들은 `nn.Conv2d`의 디폴트 설정을 그대로 따른다. 각각의 컨볼루션 층 다음에는 MaxPooling 층과 ReLu 활성화 함수를 적용하라. 마지막 컨볼루션 층의 출력에 Flatten 층을 적용한 후 적절한 크기의 3개의 Linear 층을 거쳐서 최종 출력이 나오도록 만들어라."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"VA0lfvdRbOn3"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3) # in, out, ksize\n","        self.conv2 = nn.Conv2d(16, 32, 3)\n","        self.conv3 = nn.Conv2d(32, 32, 3)\n","        self.pool2 = nn.MaxPool2d(2, 2) # ksize, stride\n","        self.pool3 = nn.MaxPool2d(3, 3) # ksize, stride\n","        self.fc1 = nn.Linear(32*3*3, 128) # in, out\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.pool2(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = self.pool3(F.relu(self.conv3(x)))\n","        # input image: 3 channel RGB image of size 50x50\n","        # ksize: 3, stride = 1(default), padding = 0(default)\n","        # conv1: (3,50,50)->(16,48,48)\n","        # pool2: (16,48,48)->(16,24,24)\n","        # conv2: (16,24,24)->(32,22,22)\n","        # pool2: (32,22,22)->(32,11,11)\n","        # conv3: (32,11,11)->(32,9,9)\n","        # pool3: (32,9,9)->(32,3,3)\n","        x = torch.flatten(x, 1) # batch를 제외한 모든 차원을 평탄화(flatten)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"wa6ghXF5c9zj","tags":[]},"source":[" 직성한 클래스 `Net`을 이용하여 네트워크를 생성하고 디바이스에 할당한다."]},{"cell_type":"code","execution_count":18,"metadata":{"deletable":false,"editable":false,"id":"3jNj61Rjc0yc","tags":[]},"outputs":[{"data":{"text/plain":["Net(\n","  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (pool3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=288, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["net = Net()\n","net.to(device)"]},{"cell_type":"markdown","metadata":{"id":"wv4ZylpCdRl6"},"source":["_______________________________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"ekJqvlVedU53","tags":[]},"source":["손실함수와 옵티마이저를 다음과 같이 정의한다."]},{"cell_type":"code","execution_count":19,"metadata":{"deletable":false,"editable":false,"id":"zDEiGyeDhnN_","tags":[]},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"]},{"cell_type":"markdown","metadata":{"id":"LceDXvXtdmGD"},"source":["__________________________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"NS6myxncdpHh","tags":[]},"source":["**문제 5:** 한 에포크(epoch)의 트레이닝을 수행하는 함수 `train`을 작성하라. 한 에포크 동안의 평균 손실(loss)을 계산하여 출력하도록 구현하라."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"zv8movAZhSaS"},"outputs":[],"source":["def train(dataloader, model, loss_fn, optimizer):\n","    # YOUR CODE HERE\n","    model.train()\n","\n","    loss_values = []\n","\n","    for X, y in dataloader:\n","        X, y = X.to(device), y.to(device)\n","\n","        # 예측 오류 계산\n","        pred = model(X)\n","        loss = loss_fn(pred, y) # pred is tensor while y is scalar, in this case pytorch automatically one-hot encodes the scalar into a tensor\n","\n","        # 역전파\n","        optimizer.zero_grad() # 수동으로 gradient 초기화\n","        loss.backward() # 역전파. 레이어 별 chain rule 적용\n","        optimizer.step()\n","\n","        # record loss\n","        loss_values.append(loss.item())\n","    print(f'Average loss: {torch.mean(torch.FloatTensor(loss_values))}')\n"]},{"cell_type":"markdown","metadata":{"id":"YLoKOtxlfRyJ"},"source":["____________________________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"vKFouyJFfVo-","tags":[]},"source":["**문제 6:** 모든 테스트 데이터를 한 번 사용하여 테스트를 수행하는 함수 `test`를 작성하라. 정확도(accuracy)를 계산하여 출력하도록 구현하라. "]},{"cell_type":"code","execution_count":21,"metadata":{"id":"CrdQvvRvfwmd"},"outputs":[],"source":["def test(dataloader, model, loss_fn):\n","    # YOUR CODE HERE\n","    model.eval()\n","\n","    test_loss, correct = 0, 0\n","    with torch.no_grad(): # create a new context where grad is not evaluated automatically\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","            # pred.argmax(<axis index>) -> returns array of indices of each subarrays' max value\n","            # pred.argmax(...) == y -> implicit type conversion [true, false, ...]\n","            # .type(torch.float) -> converts to tensor true = 1, false = 0\n","            # .sum() adds correct count\n","            # .item() unwrap underlying value from tensor\n","\n","    num_batches = len(dataloader)\n","    test_loss /= num_batches\n","    size = len(dataloader.dataset)\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"]},{"cell_type":"markdown","metadata":{"id":"353OTPFHf1cE"},"source":["_______________________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"3WJb78mIc5Yh","tags":[]},"source":["아래의 코드는 20 에포크(epoch) 동안 training을 수행한다. 매 epoch마다 평균 손실(loss)이  출력된다. 또한 매 epoch마다 테스트 데이터셋에 속한 모든 이미지를 사용하여 테스트를 수행하고 예측의 정확도를 계산하여 출력한다. "]},{"cell_type":"code","execution_count":22,"metadata":{"deletable":false,"editable":false,"id":"-RComy9zgZal","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","Average loss: 2.3044896125793457\n","Test Error: \n"," Accuracy: 10.1%, Avg loss: 2.303269 \n","\n","Epoch 2\n","-------------------------------\n","Average loss: 2.3028504848480225\n","Test Error: \n"," Accuracy: 11.9%, Avg loss: 2.302028 \n","\n","Epoch 3\n","-------------------------------\n","Average loss: 2.301818609237671\n","Test Error: \n"," Accuracy: 15.4%, Avg loss: 2.301039 \n","\n","Epoch 4\n","-------------------------------\n","Average loss: 2.3008639812469482\n","Test Error: \n"," Accuracy: 15.0%, Avg loss: 2.300013 \n","\n","Epoch 5\n","-------------------------------\n","Average loss: 2.299743413925171\n","Test Error: \n"," Accuracy: 16.0%, Avg loss: 2.298646 \n","\n","Epoch 6\n","-------------------------------\n","Average loss: 2.298100471496582\n","Test Error: \n"," Accuracy: 17.1%, Avg loss: 2.296457 \n","\n","Epoch 7\n","-------------------------------\n","Average loss: 2.295170307159424\n","Test Error: \n"," Accuracy: 17.7%, Avg loss: 2.292363 \n","\n","Epoch 8\n","-------------------------------\n","Average loss: 2.2892885208129883\n","Test Error: \n"," Accuracy: 17.8%, Avg loss: 2.283796 \n","\n","Epoch 9\n","-------------------------------\n","Average loss: 2.275502920150757\n","Test Error: \n"," Accuracy: 16.8%, Avg loss: 2.263265 \n","\n","Epoch 10\n","-------------------------------\n","Average loss: 2.2463715076446533\n","Test Error: \n"," Accuracy: 16.8%, Avg loss: 2.227641 \n","\n","Epoch 11\n","-------------------------------\n","Average loss: 2.2172043323516846\n","Test Error: \n"," Accuracy: 17.8%, Avg loss: 2.201848 \n","\n","Epoch 12\n","-------------------------------\n","Average loss: 2.198538064956665\n","Test Error: \n"," Accuracy: 18.8%, Avg loss: 2.190226 \n","\n","Epoch 13\n","-------------------------------\n","Average loss: 2.180516242980957\n","Test Error: \n"," Accuracy: 19.1%, Avg loss: 2.172143 \n","\n","Epoch 14\n","-------------------------------\n","Average loss: 2.1601669788360596\n","Test Error: \n"," Accuracy: 18.4%, Avg loss: 2.156930 \n","\n","Epoch 15\n","-------------------------------\n","Average loss: 2.1401329040527344\n","Test Error: \n"," Accuracy: 19.9%, Avg loss: 2.141289 \n","\n","Epoch 16\n","-------------------------------\n","Average loss: 2.1128268241882324\n","Test Error: \n"," Accuracy: 23.0%, Avg loss: 2.112367 \n","\n","Epoch 17\n","-------------------------------\n","Average loss: 2.0953245162963867\n","Test Error: \n"," Accuracy: 23.6%, Avg loss: 2.095754 \n","\n","Epoch 18\n","-------------------------------\n","Average loss: 2.0746965408325195\n","Test Error: \n"," Accuracy: 24.6%, Avg loss: 2.083916 \n","\n","Epoch 19\n","-------------------------------\n","Average loss: 2.0539028644561768\n","Test Error: \n"," Accuracy: 26.2%, Avg loss: 2.066556 \n","\n","Epoch 20\n","-------------------------------\n","Average loss: 2.025193214416504\n","Test Error: \n"," Accuracy: 26.5%, Avg loss: 2.033685 \n","\n","Done!\n"]}],"source":["epochs = 20\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(trainloader, net, criterion, optimizer)\n","    test(testloader, net, criterion)\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"JqKNv5WEA6J8"},"source":["___________________________________________________________"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"NgKzWD9Gnuig","tags":[]},"source":["**문제 7:** 한 개의 numpy array로 표현된 3채널 이미지와 위에서 학습한 네트워크 모델 net을 입력으로 받아서 음식의 종류를 판정하여 음식 이름과 추정확률을 출력하는 함수 `eval`을 작성하라. 이미지의 사이즈는 50*50이다. `nn.Softmax` 모듈을 이용하라."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ykOz6wVho-nm"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["# Softmax 층을 생성한다. 이것을 함수 eval 내부에서 사용하라.\n","sm = nn.Softmax(dim=1)\n","\n","# 매개변수 model은 트레이닝된 네트워크 모델이며, img는 50*50*3 크기의 numpy array이며\n","# 배열에 저장된 값은 0~255 사이의 정수이다.\n","\n","print(device)\n","\n","def eval(model, img):\n","    # YOUR CODE HERE\n","    model.eval()\n","    with torch.no_grad():\n","        img = torch.FloatTensor(img).transpose(0, 2).unsqueeze(0)\n","        model = model.to(device)\n","        img = img.to(device)\n","\n","        pred = model(img)\n","        max = sm(pred)\n","        prob, index = max.max(1)\n","        print(f\"{classes[int(index)]} with probability {prob.item()}\")\n","\n","# TODO: need to include fake images in training data\n","\n","\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"FTWPmfCjA6J9","tags":[]},"source":["아래의 코드를 실행하면 예를 들어 다음과 같이 음식 이름과 추정 확률이 출력되어야 한다:\n","\n","    `ice_cream with probability 0.20791929960250854`\n"]},{"cell_type":"code","execution_count":35,"metadata":{"deletable":false,"editable":false,"id":"DX0_2VP99aZE","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ice_cream with probability 1.0\n"]}],"source":["fakeimg = np.random.randint(256, size=(50, 50, 3))\n","eval(net, fakeimg)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1eMLHfr85snnCOMojup1fS7TwHIkrAO3T","timestamp":1664500376032}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"c46aa52e3278b26e4556183816566d8702d8efa1b51316d5eb5b7903bcd8e699"}}},"nbformat":4,"nbformat_minor":0}
