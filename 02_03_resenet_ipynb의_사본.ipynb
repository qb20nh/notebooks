{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Writing `ResNet` from Scratch in PyTorch\n",
        "\n"
      ],
      "metadata": {
        "id": "R5dbDkx70lCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 강좌는 [이 블로그](https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/)의 내용을 번역하고 부분적으로 수정한 것이다.\n",
        "\n",
        "Resnet은 Residual Connections의 개념을 도입하여 네트워크가 너무 깊을 경우 네트워크 성능이 저하되는 문제를 해결한 Computer Vision의 주요 혁신중 하나이다.\n",
        "우선 ResNet의 아키텍처와 그 뒤에 숨어있는 직관적인 아이디어를 살펴보는 것으로 시작한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "WozRbNY50-1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual Block과 `Resnet`"
      ],
      "metadata": {
        "id": "vzXMRHMm2Shi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet의 핵심 구성요소는 resudual block이다. 아래 그림이 하나의 residual block을 보여준다."
      ],
      "metadata": {
        "id": "r5s_6pGBiuMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ohheum/DS2022/7ef336792c0a4ae3044653a7e020818354656b55/assets/image-9.png\" width=\"600\" height=\"360\">\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KlEwVGZz2VkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 그림에서 보이듯이 순차적인 연결 외에 모델의 일부 계층을 건너뛰는 연결(**skipped connection**)이 있다. 건너뛰기 연결이 없을 때 이 모델이 학습해야할 매핑을 `H(x)`라고 한다면 건너뛰기 연결을 추가할 경우 순차 연결 부분이 학습해야할 매핑은 `F(x) = H(x) - x`가 될 것이다. 이 잔여(residual) 매핑  `F(x)`를 학습하는 것이 원래의 매핑 `H(x)`를 학습하는 것보다 쉽다. (극단적인 예로 `H(x)`가 identity mapping이라면 residual mapping F(x)는 zero mapping이다. identity mapping보다는 zero mapping이 학습하기 쉬울 것이다.)\n",
        "\n",
        "아래는 34 레이어 ResNet의 아키텍처입니다."
      ],
      "metadata": {
        "id": "JVvyo-S74fwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/ohheum/DS2022/7ef336792c0a4ae3044653a7e020818354656b55/assets/image-10.png\" width=\"800\" height=\"1800\">"
      ],
      "metadata": {
        "id": "tjNFuA564Y4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "lwXbI5YL4lY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR-10 데이터 세트를 사용한다. CIFAR-10 데이터 세트는 10개 클래스의 60000개의 32x32 컬러 이미지로 구성되며 클래스당 6000개의 이미지가 있다. 50000개의 훈련 이미지와 10000개의 테스트 이미지가 있다.\n",
        "\n",
        "데이터 세트는 각각 10000개의 이미지가 있는 5개의 훈련 배치와 1개의 테스트 배치로 나뉜다. 테스트 배치에는 각 클래스에서 무작위로 선택된 정확히 1000개의 이미지가 포함된다. 학습 배치에는 나머지 이미지가 무작위 순서로 포함되지만 일부 학습 배치에는 한 클래스의 이미지가 다른 클래스보다 더 많을 수 있다. "
      ],
      "metadata": {
        "id": "5UCTxdK34nQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://pytorch.org/tutorials/_images/cifar10.png\" width=\"600\" height=\"420\">"
      ],
      "metadata": {
        "id": "jWr1MnUY4uqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Libraries"
      ],
      "metadata": {
        "id": "pd1kloIX48Qm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3x85MEgYZcvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9c1f80-5a47-49c5-eb2c-d0f225e42fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "M-phgx7a5AMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "토치비전 라이브러리를 사용하여 데이터 세트를 로드한다."
      ],
      "metadata": {
        "id": "xjTM5TIC5DsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 아래의의 `data_loader` 함수는 트레이닝 데이터와 테스트 데이터에 대한 `DataLoader`를 생성하여 반환한다. \n",
        "* 데이터 세트의 각 채널(빨간색, 녹색 및 파란색)의 평균 및 표준 편차로 정규화를 수행한다.\n",
        "* 데이터 로더를 사용하면 데이터를 일괄적으로 반복할 수 있으며 데이터는 반복하는 동안 로드되며 시작 시 한 번에 모두 RAM에 로드되지는 않는다. 이것은 대규모 데이터 세트를 처리하는 경우 매우 유용하다.\n",
        "* 매개변수 `test=False`인 경우 트레이닝 분할을, `test=True`인 경우 테스트 분할을 로드한다. train의 경우 분할은 무작위로 train과 validation set(0.9:0.1)으로 나뉜다."
      ],
      "metadata": {
        "id": "VyT0X42N5OVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader(data_dir,\n",
        "                batch_size,\n",
        "                random_seed=42,\n",
        "                valid_size=0.1,\n",
        "                shuffle=True,\n",
        "                test=False):\n",
        "  \n",
        "    normalize = transforms.Normalize( # empirical parameter, probably mean and stddev of whole dataset\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "    # define transforms\n",
        "    transform = transforms.Compose([ # function composition\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "\n",
        "    if test:\n",
        "        dataset = datasets.CIFAR10(\n",
        "          root=data_dir, train=False,\n",
        "          download=True, transform=transform,\n",
        "        )\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=batch_size, shuffle=shuffle\n",
        "        )\n",
        "\n",
        "        return data_loader\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train)) # list of [0, ..., num_train-1]\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(42)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        " \n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "# CIFAR10 dataset \n",
        "train_loader, valid_loader = data_loader(data_dir='./data',\n",
        "                                         batch_size=64)\n",
        "\n",
        "test_loader = data_loader(data_dir='./data',\n",
        "                              batch_size=64,\n",
        "                              test=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfiQ5edcZvVi",
        "outputId": "581e7e50-e6fb-438d-da81-30900643a175"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How models work in PyTorch"
      ],
      "metadata": {
        "id": "Ur-7NAIm5gDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ResNet에는 PyTorch가 제공하는 다양한 유형의 레이어가 사용된다.\n",
        "\n",
        "* nn.Conv2d: 커널 크기와 함께 입력 및 출력 채널의 수를 인수로 받아들이는 컨볼루션 계층. \n",
        "* nn.BatchNorm2d: 컨볼루션 레이어의 출력에 일괄 정규화를 적용, 각 레이어 정규화 하는데 그 정규화 파라메터도 최적화\n",
        "* nn.ReLU: 네트워크의 다양한 출력에 적용되는 활성화 함수\n",
        "* nn.MaxPool2d : 최대 풀링을 적용\n",
        "* nn.Dropout: 주어진 확률로 출력에 드롭아웃을 적용 (prob 을 줘서 레이어 각 아웃풋을 prob확률로 0으로 강제), overfit 방지\n",
        "* nn.Linear: 완전히 연결된 레이어\n",
        "* nn.Sequential: 여러 계층을 결합하는데 사용됨"
      ],
      "metadata": {
        "id": "q6u8780k5jc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual Block"
      ],
      "metadata": {
        "id": "EqD9C1Qe5s3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 네트워크 전체에서 재사용할 수 있는 ResidualBlock을 정의한다. "
      ],
      "metadata": {
        "id": "OYFue1Gy5vJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels),\n",
        "                        nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(\n",
        "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels))\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample: # stride에 따라 residual과 x의 사이즈 일치시키기 위한 operation\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "8HZ8Tb00ZzCJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet"
      ],
      "metadata": {
        "id": "dMABgdVS51t9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 ResidualBlock을 만들었으므로 ResNet을 빌드할 수 있다.\n",
        "\n",
        "아키텍처에는 각각 3, 3, 6, 3개의 레이어를 포함하는 3개의 블록이 있다. 이 블록을 만들기 위해 도우미 함수 _make_layer를 만든다. 이 기능은 Residual Block과 함께 레이어를 하나씩 추가한다. 블록 다음에 평균 풀링과 최종 선형 레이어를 추가한다."
      ],
      "metadata": {
        "id": "P4rV_1Og53Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU())\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
        "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
        "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
        "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):     # x.shape=(3,224,224)\n",
        "        x = self.conv1(x)     # (112, 112)\n",
        "        x = self.maxpool(x)   # (56, 56)\n",
        "        x = self.layer0(x)    # (56, 56)\n",
        "        x = self.layer1(x)    # (28, 28)\n",
        "        x = self.layer2(x)    # (14, 14)\n",
        "        x = self.layer3(x)    # (7, 7)\n",
        "\n",
        "        x = self.avgpool(x)   # (1,1)\n",
        "        x = x.view(x.size(0), -1)   # 512 # flatten\n",
        "        x = self.fc(x)        \n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "msVMW6gxZ4ap"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Hyperparameters"
      ],
      "metadata": {
        "id": "bIzlULci582f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = ResNet(ResidualBlock, [3, 4, 6, 3]).to(device)\n",
        "\n",
        "from torchsummary import summary\n",
        "print(summary(model, (3, 224, 224)))\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)  \n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "QqURongpZ6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11471a9a-60c3-458c-8fa5-4fb856c50090"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "    ResidualBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "             ReLU-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "             ReLU-24           [-1, 64, 56, 56]               0\n",
            "    ResidualBlock-25           [-1, 64, 56, 56]               0\n",
            "           Conv2d-26          [-1, 128, 28, 28]          73,856\n",
            "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
            "             ReLU-28          [-1, 128, 28, 28]               0\n",
            "           Conv2d-29          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
            "           Conv2d-31          [-1, 128, 28, 28]           8,320\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "    ResidualBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
            "             ReLU-37          [-1, 128, 28, 28]               0\n",
            "           Conv2d-38          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
            "             ReLU-40          [-1, 128, 28, 28]               0\n",
            "    ResidualBlock-41          [-1, 128, 28, 28]               0\n",
            "           Conv2d-42          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
            "             ReLU-44          [-1, 128, 28, 28]               0\n",
            "           Conv2d-45          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
            "             ReLU-47          [-1, 128, 28, 28]               0\n",
            "    ResidualBlock-48          [-1, 128, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "    ResidualBlock-55          [-1, 128, 28, 28]               0\n",
            "           Conv2d-56          [-1, 256, 14, 14]         295,168\n",
            "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
            "             ReLU-58          [-1, 256, 14, 14]               0\n",
            "           Conv2d-59          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
            "           Conv2d-61          [-1, 256, 14, 14]          33,024\n",
            "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
            "             ReLU-63          [-1, 256, 14, 14]               0\n",
            "    ResidualBlock-64          [-1, 256, 14, 14]               0\n",
            "           Conv2d-65          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
            "             ReLU-67          [-1, 256, 14, 14]               0\n",
            "           Conv2d-68          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
            "             ReLU-70          [-1, 256, 14, 14]               0\n",
            "    ResidualBlock-71          [-1, 256, 14, 14]               0\n",
            "           Conv2d-72          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
            "             ReLU-74          [-1, 256, 14, 14]               0\n",
            "           Conv2d-75          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
            "             ReLU-77          [-1, 256, 14, 14]               0\n",
            "    ResidualBlock-78          [-1, 256, 14, 14]               0\n",
            "           Conv2d-79          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
            "             ReLU-81          [-1, 256, 14, 14]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "    ResidualBlock-85          [-1, 256, 14, 14]               0\n",
            "           Conv2d-86          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
            "             ReLU-88          [-1, 256, 14, 14]               0\n",
            "           Conv2d-89          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
            "             ReLU-91          [-1, 256, 14, 14]               0\n",
            "    ResidualBlock-92          [-1, 256, 14, 14]               0\n",
            "           Conv2d-93          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
            "             ReLU-95          [-1, 256, 14, 14]               0\n",
            "           Conv2d-96          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
            "             ReLU-98          [-1, 256, 14, 14]               0\n",
            "    ResidualBlock-99          [-1, 256, 14, 14]               0\n",
            "          Conv2d-100            [-1, 512, 7, 7]       1,180,160\n",
            "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-102            [-1, 512, 7, 7]               0\n",
            "          Conv2d-103            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
            "          Conv2d-105            [-1, 512, 7, 7]         131,584\n",
            "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-107            [-1, 512, 7, 7]               0\n",
            "   ResidualBlock-108            [-1, 512, 7, 7]               0\n",
            "          Conv2d-109            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-111            [-1, 512, 7, 7]               0\n",
            "          Conv2d-112            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-114            [-1, 512, 7, 7]               0\n",
            "   ResidualBlock-115            [-1, 512, 7, 7]               0\n",
            "          Conv2d-116            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-118            [-1, 512, 7, 7]               0\n",
            "          Conv2d-119            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-121            [-1, 512, 7, 7]               0\n",
            "   ResidualBlock-122            [-1, 512, 7, 7]               0\n",
            "       AvgPool2d-123            [-1, 512, 1, 1]               0\n",
            "          Linear-124                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 21,298,314\n",
            "Trainable params: 21,298,314\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 96.28\n",
            "Params size (MB): 81.25\n",
            "Estimated Total Size (MB): 178.10\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "KwfVZC536C8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        del images, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, loss.item()))\n",
        "            \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "    \n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) "
      ],
      "metadata": {
        "id": "Wr-1vzX5Z9XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드의 출력을 보면 매 에포크마다 검증(validation) 세트의 정확도가 증가하고 손실이 감소함에 따라 모델이 학습하고 있음을 알 수 있다. "
      ],
      "metadata": {
        "id": "6DdUOW0j6QIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "yyaey-7C6WG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트를 위해 유효성 검사와 정확히 동일한 코드를 사용하지만 test_loader를 사용한다."
      ],
      "metadata": {
        "id": "scU8tvDD6XsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve5OoeR6aKx5",
        "outputId": "465344b4-780f-4b2d-cc66-993fd83328ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 83.93 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "위의 코드를 사용하고 10개의 에포크 동안 모델을 훈련하여 테스트 세트에서 82.87%의 정확도를 달성할 수 있었다."
      ],
      "metadata": {
        "id": "2JULaEu1g01L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8x0XSKjqAa_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}